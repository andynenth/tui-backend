# Phase Transition Bug Fix - MINIMAL CONNECTIVITY RESTORATION PLAN

**Document Purpose**: ONLY connect existing broken components - NO NEW FEATURES ALLOWED  
**Priority**: CRITICAL - Game is stuck in PREPARATION phase, no event persistence  
**Estimated Time**: 1 hour maximum - minimal fixes only  
**Constraint**: STRICT NO NEW FEATURES - Only enable/connect existing code  
**Created**: 2025-01-01  
**Updated**: 2025-01-02 - Architecture confusion prevention completed  

## üéØ STATUS: ARCHITECTURE FOUNDATION COMPLETED

**MAJOR UPDATE**: Architecture confusion prevention measures have been implemented to address the root causes identified in this plan.

### ‚úÖ **Completed Architecture Prevention Work:**
- **Architecture Decision Record (ADR)**: Created comprehensive documentation of Clean Architecture vs Engine Layer boundaries
- **Quick Architecture Reference**: Created terminology glossary and decision-making guide  
- **Change Protocols**: Established mandatory checklists for architectural changes
- **Validation Scripts**: Implemented automated boundary checking (validate_architecture.py, check_dependencies.py, validate_feature_flags.py)
- **Pre-commit Hooks**: Added automated enforcement of architectural boundaries
- **Component Interaction Diagrams**: Created visual guides for proper integration patterns

### üõ°Ô∏è **Root Causes Now Addressed:**
- **Layer Boundary Violations**: Automated detection via pre-commit hooks
- **Duplicate Business Logic**: Clear separation guidelines in documentation
- **Architecture Gaps**: Comprehensive integration patterns documented
- **Feature Flag Misuse**: Validation scripts ensure proper usage

**Next Step**: The minimal connectivity restoration can now proceed with full architectural protection in place.  

## üéØ Executive Summary

**Root Cause Identified**: Event sourcing disabled + State machine operates independently from Clean Architecture domain layer, breaking both event persistence and proper business logic flow.

**Clean Architecture Analysis**:
- ‚ùå **Layer Boundary Violation**: `application/use_cases/game/start_game.py:106` bypasses state machine, calling domain directly
- ‚ùå **Duplicate Business Logic**: Domain `GamePhase` enum + State machine `GamePhase` enum create inconsistency
- ‚ùå **Infrastructure Bypass**: Events broadcast but not persisted due to disabled event sourcing
- ‚ùå **Architecture Gap**: State machine exists as engine layer, not integrated with Clean Architecture

**Impact**: 
- ‚ùå Events broadcast to frontend but never persisted (infrastructure layer issue)
- ‚ùå Game gets stuck in PREPARATION phase (application layer bypasses state machine)
- ‚ùå No state recovery or replay capability (event sourcing disabled)
- ‚ùå Sophisticated state machine logic bypassed (Clean Architecture integration missing)
- ‚ùå Domain business rules duplicated in state machine (DRY violation)

**Clean Architecture Solution**: Enable event sourcing + Integrate state machine as infrastructure service + Preserve domain layer purity + Ensure proper dependency flow.

## üìã Implementation Phases

### **Phase 1: Enable Event Sourcing Foundation** üîß
*Prerequisites: None*  
*Estimated Time: 15 minutes*  
*Risk Level: MINIMAL - Just enabling existing infrastructure*

#### **Granular Tasks:**

##### **Task 1.1: Enable Event Sourcing Feature Flag**
- [ ] **1.1.1**: Locate feature flag file
  - **Action**: Navigate to `backend/infrastructure/feature_flags.py`
  - **Validation**: File exists and contains `USE_EVENT_SOURCING` property
  - **Time**: 2 minutes
  - **Success Criteria**: File opened and flag located at line ~85

- [ ] **1.1.2**: Change feature flag value
  - **Action**: Change `self.USE_EVENT_SOURCING = False` to `self.USE_EVENT_SOURCING = True`
  - **Validation**: Only this single line changed, no other modifications
  - **Time**: 1 minute
  - **Success Criteria**: Git diff shows exactly 1 line changed

- [ ] **1.1.3**: Test feature flag activation
  - **Action**: Run basic feature flag test to verify activation
  - **Command**: `python -c "from backend.infrastructure.feature_flags import get_feature_flags; flags = get_feature_flags(); print(f'Event sourcing enabled: {flags.is_enabled(flags.USE_EVENT_SOURCING, {})}')"`
  - **Time**: 2 minutes
  - **Success Criteria**: Output shows `Event sourcing enabled: True`

##### **Task 1.2: Verify EventStore Database Accessibility**
- [ ] **1.2.1**: Check EventStore service file exists
  - **Action**: Verify `backend/api/services/event_store.py` file exists
  - **Validation**: File is present and readable
  - **Time**: 1 minute
  - **Success Criteria**: File exists and contains EventStore class

- [ ] **1.2.2**: Test database connection
  - **Action**: Run SQLite database health check
  - **Command**: `python -c "from backend.api.services.event_store import EventStore; store = EventStore(); print('Database accessible:', store.is_healthy())"`
  - **Time**: 3 minutes
  - **Success Criteria**: Database connection successful, no errors

- [ ] **1.2.3**: Verify database schema
  - **Action**: Check that events table exists in SQLite database
  - **Command**: `sqlite3 backend/data/events.db ".schema events"`
  - **Time**: 2 minutes
  - **Success Criteria**: Events table schema displayed without errors

##### **Task 1.3: Validate CompositeEventPublisher Creation**
- [ ] **1.3.1**: Verify dependency injection setup
  - **Action**: Check `backend/infrastructure/dependencies.py` lines 96-109
  - **Validation**: CompositeEventPublisher creation logic exists
  - **Time**: 2 minutes
  - **Success Criteria**: Code shows conditional creation based on USE_EVENT_SOURCING flag

- [ ] **1.3.2**: Test CompositeEventPublisher instantiation
  - **Action**: Import and instantiate EventPublisher with feature flag enabled
  - **Command**: `python -c "from backend.infrastructure.dependencies import get_container; container = get_container(); publisher = container.get('EventPublisher'); print(f'Publisher type: {type(publisher).__name__}')"`
  - **Time**: 2 minutes
  - **Success Criteria**: Output shows `Publisher type: CompositeEventPublisher`

- [ ] **1.3.3**: Verify publisher count
  - **Action**: Check that CompositeEventPublisher contains both WebSocket and EventStore publishers
  - **Command**: `python -c "from backend.infrastructure.dependencies import get_container; container = get_container(); publisher = container.get('EventPublisher'); print(f'Publisher count: {len(publisher._publishers)}')"`
  - **Time**: 1 minute
  - **Success Criteria**: Output shows `Publisher count: 2`

#### **Success Criteria:**
- ‚úÖ Event sourcing feature flag enabled
- ‚úÖ CompositeEventPublisher created with 2 publishers
- ‚úÖ EventStore database accessible
- ‚úÖ No dependency injection errors

#### **Test Units:**
```python
# Test 1.1: Feature Flag Enabled
def test_event_sourcing_enabled():
    flags = get_feature_flags()
    assert flags.is_enabled(flags.USE_EVENT_SOURCING) == True

# Test 1.2: CompositeEventPublisher Creation
def test_composite_publisher_created():
    container = get_container()
    publisher = container.get(EventPublisher)
    assert isinstance(publisher, CompositeEventPublisher)
    assert len(publisher._publishers) == 2

# Test 1.3: EventStore Database Health
def test_event_store_health():
    health = await event_store.health_check()
    assert health["status"] == "healthy"
    assert health["database_accessible"] == True
```

---

### **Phase 2: Connect State Machine to Use Cases** ‚úÖ
*Prerequisites: Phase 1 complete*  
*Estimated Time: 30 minutes*  
*Risk Level: LOW - Modifying existing files only*

#### **Granular Tasks:**

##### **Task 2.1: Analyze Current Use Case Implementation**
- [ ] **2.1.1**: Read current StartGameUseCase implementation
  - **Action**: Open and analyze `backend/application/use_cases/game/start_game.py`
  - **Focus**: Line 106 and surrounding logic that bypasses state machine
  - **Time**: 5 minutes
  - **Success Criteria**: Understand current flow and identify exact bypass point

- [ ] **2.1.2**: Identify state machine integration points
  - **Action**: Locate existing state machine imports and integration code
  - **Validation**: Find where GameStateMachine is available but not used
  - **Time**: 3 minutes
  - **Success Criteria**: Clear understanding of what needs to be connected

- [ ] **2.1.3**: Plan minimal modification approach
  - **Action**: Design exact line changes needed to use state machine
  - **Constraint**: Must use existing state machine, no new functionality
  - **Time**: 2 minutes
  - **Success Criteria**: Clear plan for <5 line changes maximum

##### **Task 2.2: Modify StartGameUseCase State Machine Integration**
- [ ] **2.2.1**: Backup current implementation
  - **Action**: Create backup copy of current start_game.py
  - **Command**: `cp backend/application/use_cases/game/start_game.py backend/application/use_cases/game/start_game.py.backup`
  - **Time**: 1 minute
  - **Success Criteria**: Backup file created successfully

- [ ] **2.2.2**: Replace direct domain call with state machine coordination
  - **Action**: Modify line ~106 from `game.start_round()` to use state machine
  - **Change**: Replace direct call with state machine transition
  - **Validation**: Only modify existing line, don't add new logic
  - **Time**: 5 minutes
  - **Success Criteria**: Git diff shows minimal, targeted change

- [ ] **2.2.3**: Test basic compilation
  - **Action**: Run basic syntax check on modified file
  - **Command**: `python -m py_compile backend/application/use_cases/game/start_game.py`
  - **Time**: 2 minutes
  - **Success Criteria**: No syntax errors, file compiles successfully

##### **Task 2.3: Verify State Machine Domain Integration**
- [ ] **2.3.1**: Check PreparationState implementation
  - **Action**: Read `backend/engine/state_machine/states/preparation_state.py`
  - **Validation**: Confirm it calls domain methods appropriately
  - **Time**: 5 minutes
  - **Success Criteria**: State machine enhances rather than replaces domain logic

- [ ] **2.3.2**: Verify automatic progression logic
  - **Action**: Review timeout and progression conditions in PreparationState
  - **Validation**: Ensure progression triggers are reasonable and working
  - **Time**: 3 minutes
  - **Success Criteria**: Automatic progression to DECLARATION phase exists

- [ ] **2.3.3**: Test state machine domain method calls
  - **Action**: Verify state machine calls existing domain business rules
  - **Command**: `grep -n "game\." backend/engine/state_machine/states/preparation_state.py`
  - **Time**: 2 minutes
  - **Success Criteria**: State machine properly delegates to domain layer

##### **Task 2.4: Integration Testing Preparation**
- [ ] **2.4.1**: Create simple integration test script
  - **Action**: Write minimal test to verify use case ‚Üí state machine ‚Üí domain flow
  - **File**: Create `test_phase2_integration.py` in test directory
  - **Time**: 10 minutes
  - **Success Criteria**: Test script ready to validate integration

- [ ] **2.4.2**: Test modified use case in isolation
  - **Action**: Run modified StartGameUseCase with mock dependencies
  - **Validation**: Ensure no immediate errors or exceptions
  - **Time**: 5 minutes
  - **Success Criteria**: Use case executes without crashing

- [ ] **2.4.3**: Verify event publishing chain
  - **Action**: Confirm events flow from state machine through use case to publishers
  - **Test**: Mock event publishers and verify they receive state transition events
  - **Time**: 8 minutes
  - **Success Criteria**: Event chain intact, no broken connections

#### **Success Criteria:**
- ‚úÖ Use case calls state machine instead of bypassing it
- ‚úÖ State machine uses existing domain business rules
- ‚úÖ No new features added, only existing connections fixed

#### **Test Units:**
```python
# Test 2.1: End-to-End Event Persistence
async def test_event_persistence_chain():
    # Trigger StartGameUseCase
    response = await start_game_use_case.execute(request)
    
    # Verify WebSocket broadcast (mock)
    assert mock_websocket.call_count > 0
    
    # Verify database persistence
    events = await event_store.get_room_events(room_id)
    assert len(events) > 0
    assert any(e.event_type == "game_started" for e in events)

# Test 2.2: EventStorePublisher Direct Test
async def test_event_store_publisher():
    publisher = EventStorePublisher(event_store)
    test_event = GameStarted(room_id="test", ...)
    
    await publisher.publish(test_event)
    
    events = await event_store.get_room_events("test")
    assert len(events) == 1
    assert events[0].event_type == "game_started"

# Test 2.3: Event Serialization Round-Trip
def test_event_serialization():
    original_event = GameStarted(room_id="test", player_count=4)
    serialized = original_event.to_dict()
    deserialized = GameStarted.from_dict(serialized)
    assert original_event == deserialized
```

---

### **Phase 3: Test Integration** üöÄ
*Prerequisites: Phase 2 complete*  
*Estimated Time: 15 minutes*  
*Risk Level: MINIMAL - Testing existing functionality*

#### **Granular Tasks:**

##### **Task 3.1: Validate Phase Progression Fix**
- [ ] **3.1.1**: Set up test environment
  - **Action**: Ensure test database is clean and ready
  - **Command**: `rm -f backend/data/events_test.db && python setup_test_db.py`
  - **Time**: 2 minutes
  - **Success Criteria**: Clean test environment ready

- [ ] **3.1.2**: Start game and monitor phase progression
  - **Action**: Execute StartGameUseCase and track phase changes
  - **Test Script**: Run integration test with timer to monitor progression
  - **Time**: 5 minutes
  - **Success Criteria**: Game transitions from PREPARATION to DECLARATION within 10 seconds

- [ ] **3.1.3**: Verify no infinite loops or stuck states
  - **Action**: Monitor for 30 seconds to ensure stable progression
  - **Validation**: No repeated phase transitions or error loops
  - **Time**: 3 minutes
  - **Success Criteria**: Single clean transition, no loops or errors

##### **Task 3.2: Validate Event Persistence**
- [ ] **3.2.1**: Trigger game start with event tracking
  - **Action**: Start game while monitoring event store writes
  - **Monitor**: Watch SQLite database for event insertions
  - **Time**: 3 minutes
  - **Success Criteria**: Events appear in database during game start

- [ ] **3.2.2**: Verify event content and structure
  - **Action**: Query events table and validate event data
  - **Command**: `sqlite3 backend/data/events_test.db "SELECT * FROM events WHERE room_id='test_room'"`
  - **Time**: 2 minutes
  - **Success Criteria**: Events contain correct room_id, event_type, and payload data

- [ ] **3.2.3**: Test event retrieval and replay
  - **Action**: Retrieve events from store and verify they can be parsed
  - **Test**: Load events and reconstruct game state
  - **Time**: 5 minutes
  - **Success Criteria**: Events can be retrieved and parsed without errors

##### **Task 3.3: Validate WebSocket Functionality**
- [ ] **3.3.1**: Mock WebSocket connection
  - **Action**: Set up mock WebSocket client to receive events
  - **Setup**: Create test WebSocket listener
  - **Time**: 3 minutes
  - **Success Criteria**: Mock WebSocket ready to receive events

- [ ] **3.3.2**: Trigger game start and monitor WebSocket events
  - **Action**: Start game and capture WebSocket messages
  - **Validation**: Ensure WebSocket events are still published
  - **Time**: 2 minutes
  - **Success Criteria**: WebSocket receives game_started and phase_change events

- [ ] **3.3.3**: Verify no regression in real-time updates
  - **Action**: Compare WebSocket event timing with previous behavior
  - **Test**: Ensure events arrive within expected timeframe (<1 second)
  - **Time**: 3 minutes
  - **Success Criteria**: WebSocket events arrive promptly, no performance regression

##### **Task 3.4: End-to-End Integration Validation**
- [ ] **3.4.1**: Run complete game flow test
  - **Action**: Execute full sequence: create room ‚Üí join players ‚Üí start game ‚Üí verify progression
  - **Time**: 5 minutes
  - **Success Criteria**: Complete flow works without errors

- [ ] **3.4.2**: Validate both persistence channels working together
  - **Action**: Confirm both WebSocket and database events occur simultaneously
  - **Test**: Monitor both channels during single game start
  - **Time**: 3 minutes
  - **Success Criteria**: Events appear in both WebSocket and database

- [ ] **3.4.3**: Performance baseline check
  - **Action**: Measure response times for game start operation
  - **Benchmark**: Compare with expected performance (<500ms for game start)
  - **Time**: 2 minutes
  - **Success Criteria**: No significant performance degradation from integration

#### **Simple Success Criteria:**
- ‚úÖ Game automatically progresses from PREPARATION to DECLARATION phase
- ‚úÖ Events persist to database (not just WebSocket)
- ‚úÖ No existing functionality broken
- ‚úÖ No new features added
- ‚úÖ Minimal code changes (< 10 lines modified total)

#### **Test Units:**
```python
# Test 3.1: Automatic Phase Progression
async def test_preparation_phase_progression():
    # Start game in PREPARATION phase
    game = create_test_game()
    state_machine = GameStateMachine(game)
    
    # Trigger progression conditions
    await state_machine.transition_to(GamePhase.PREPARATION)
    
    # Wait for automatic progression
    await asyncio.sleep(6)  # Allow timeout progression
    
    assert state_machine.current_phase == GamePhase.DECLARATION

# Test 3.2: State Machine Domain Integration
async def test_state_machine_domain_integration():
    use_case = StartGameUseCase(unit_of_work, event_publisher)
    response = await use_case.execute(request)
    
    # Verify state machine was used
    game = await unit_of_work.games.find_by_room_id(room_id)
    assert hasattr(game, '_state_machine')
    assert game.current_phase != GamePhase.WAITING

# Test 3.3: Phase Transition Events
async def test_phase_transition_events():
    # Monitor event store during phase transition
    initial_count = len(await event_store.get_room_events(room_id))
    
    # Trigger phase transition
    await state_machine.transition_to(GamePhase.DECLARATION)
    
    # Verify phase change event was persisted
    events = await event_store.get_room_events(room_id)
    phase_events = [e for e in events if e.event_type == "phase_change"]
    assert len(phase_events) > 0
    
    latest_phase_event = phase_events[-1]
    assert latest_phase_event.payload["new_phase"] == "declaration"
```

---

## üö® **STRICT NO NEW FEATURES ENFORCEMENT**

**ABSOLUTE RULE**: This plan ONLY connects existing broken functionality. ZERO new code allowed.

### ‚ùå **COMPLETELY FORBIDDEN (Will Abort Plan):**
- ‚ùå New game features, mechanics, or rules
- ‚ùå Additional APIs, endpoints, or routes
- ‚ùå New business logic or domain rules
- ‚ùå Enhanced monitoring, logging, or metrics
- ‚ùå Additional documentation or config files
- ‚ùå New database tables, columns, or schemas
- ‚ùå New classes, interfaces, or abstractions
- ‚ùå Additional error handling beyond existing
- ‚ùå Performance optimizations or enhancements
- ‚ùå New tests beyond validating existing functionality

### ‚úÖ **ONLY ALLOWED (Minimal Fixes):**
- ‚úÖ Change 1 line: `USE_EVENT_SOURCING: False ‚Üí True`
- ‚úÖ Modify existing use case to call existing state machine
- ‚úÖ Connect existing components that are already built
- ‚úÖ Enable existing infrastructure that's already coded

### üõ°Ô∏è **ENFORCEMENT MECHANISMS:**

#### **Pre-Implementation Validation:**
- [ ] **Line Count Limit**: Total changes must be < 10 lines
- [ ] **File Count Limit**: Modify < 5 existing files, create 0 new files
- [ ] **Feature Flag Check**: Only enable existing flags, never create new ones
- [ ] **Code Addition Ban**: No new functions, classes, or methods

#### **During Implementation Validation:**
- [ ] **Real-time Monitoring**: Each change reviewed for feature creep
- [ ] **Diff Analysis**: Git diff must show only connectivity changes
- [ ] **Architecture Boundary Check**: No new layer violations
- [ ] **Existing Code Only**: Must use infrastructure already present

#### **Post-Implementation Validation:**
- [ ] **Functionality Test**: Only test that existing features work again
- [ ] **Performance Test**: No performance improvements expected
- [ ] **Feature Audit**: Confirm zero new capabilities added
- [ ] **Rollback Ready**: Changes so minimal rollback takes < 5 minutes

#### **Clean Architecture Validation Tasks:**

- [ ] **Task 4.1**: Layer Boundary Compliance Testing
  - **Test**: Verify no circular dependencies introduced
  - **Validation**: Domain layer has zero infrastructure dependencies
  - **Tools**: Architecture testing, dependency analysis
  - **Success**: Clean Architecture boundaries maintained post-integration

- [ ] **Task 4.2**: End-to-end game flow with architecture validation
  - **Flow**: Player 1 ‚Üí Enter Lobby ‚Üí Create Room ‚Üí Start Game ‚Üí Automatic progression
  - **Verification**: Game progresses through PREPARATION ‚Üí DECLARATION with proper layer communication
  - **Architecture Check**: Events flow Domain ‚Üí Application ‚Üí Infrastructure ‚Üí API
  - **Tools**: Playwright MCP + architecture compliance validation

- [ ] **Task 4.3**: State recovery with Clean Architecture integrity
  - **Action**: Simulate server restart, verify state recovers through proper layer reconstruction
  - **Test**: Event sourcing rebuilds domain state through application layer orchestration
  - **Validation**: State recovery respects Clean Architecture patterns
  - **Architecture Check**: Infrastructure event store ‚Üí Application use case ‚Üí Domain entity reconstruction

- [ ] **Task 4.4**: Performance with Clean Architecture overhead
  - **Metrics**: Event publishing latency, layer communication overhead, memory usage
  - **Benchmark**: Compare Clean Architecture vs direct calls performance
  - **Threshold**: <10ms event latency with proper layer separation maintained
  - **Validation**: Architecture compliance doesn't compromise real-time game performance

- [ ] **Task 4.5**: Error handling with layer isolation
  - **Scenarios**: Database unavailable, state machine errors, domain validation failures
  - **Expected**: Errors isolated to appropriate layers, graceful degradation
  - **Architecture Check**: Error handling respects layer boundaries and dependency directions

#### **Clean Architecture Success Criteria:**
- ‚úÖ Full game flow works end-to-end while maintaining Clean Architecture
- ‚úÖ State recovery from events functional through proper layer orchestration
- ‚úÖ Performance within acceptable limits (<10ms latency) with layer separation
- ‚úÖ Error scenarios handled gracefully within appropriate layer boundaries
- ‚úÖ No Clean Architecture violations introduced during integration
- ‚úÖ Domain layer business logic remains pure and testable
- ‚úÖ Infrastructure layer properly implements application interfaces
- ‚úÖ Application layer coordinates without implementing business logic

#### **Test Units:**
```python
# Test 4.1: End-to-End Game Flow
async def test_complete_game_flow():
    # Start with fresh game
    room_id = await create_test_room()
    
    # Start game
    await start_game(room_id, host_player_id)
    
    # Wait for automatic progression
    await asyncio.sleep(10)
    
    # Verify progression occurred
    events = await event_store.get_room_events(room_id)
    phase_events = [e for e in events if e.event_type == "phase_change"]
    
    # Should have: waiting ‚Üí preparation ‚Üí declaration
    assert len(phase_events) >= 2
    phases = [e.payload["new_phase"] for e in phase_events]
    assert "preparation" in phases
    assert "declaration" in phases

# Test 4.2: State Recovery
async def test_state_recovery():
    # Create game with known state
    room_id = "recovery_test"
    await start_game(room_id, host_player_id)
    await progress_to_declaration_phase(room_id)
    
    # Simulate server restart - clear in-memory state
    clear_in_memory_game_state(room_id)
    
    # Recovery state from events
    recovered_state = await event_store.replay_room_state(room_id)
    
    # Verify state matches expected
    assert recovered_state["phase"] == "declaration"
    assert recovered_state["round_number"] == 1
    assert len(recovered_state["players"]) == 4

# Test 4.3: Performance Regression
async def test_performance_metrics():
    start_time = time.time()
    
    # Perform typical operations
    for i in range(100):
        await event_publisher.publish(test_event)
    
    end_time = time.time()
    avg_latency = (end_time - start_time) / 100
    
    assert avg_latency < 0.01  # Less than 10ms per event
```

---

### **Success Validation** üéØ
*Prerequisites: Phase 3 complete*  
*Validation Time: 5 minutes*  
*Risk Level: NONE - Just checking existing functionality works*

#### **Tasks:**
- [ ] **Task 5.1**: Configuration validation
  - **Action**: Verify feature flags are properly set for production
  - **Files**: Environment variables, config files
  - **Test**: Feature flag override mechanisms work

- [ ] **Task 5.2**: Monitoring and logging
  - **Action**: Ensure proper logging for event sourcing operations
  - **Metrics**: Event processing rates, error rates, database health
  - **Alerts**: Set up monitoring for event store failures

- [ ] **Task 5.3**: Documentation updates
  - **Action**: Update architecture docs to reflect event sourcing status
  - **Files**: `ARCHITECTURE_OVERVIEW.md`, `BACKEND_LAYER_ANALYSIS.md`
  - **Content**: Event sourcing enabled, phase progression fixed

- [ ] **Task 5.4**: Deployment checklist
  - **Database**: Ensure SQLite permissions and storage
  - **Feature Flags**: Production configuration
  - **Dependencies**: All required packages installed

#### **Success Criteria:**
- ‚úÖ Production configuration validated
- ‚úÖ Monitoring and logging operational
- ‚úÖ Documentation updated
- ‚úÖ Deployment ready

---

## ü§ñ Minimal Fix Agent Configuration

**Strategy**: Connect existing components without adding new features

### **Simplified Agent Configuration (4 Agents Only)**

Focus on connecting existing pieces, not building new ones:

```javascript
// MINIMAL FIX DEPLOYMENT - NO NEW FEATURES
[Single Message - Batch Execution]:
  mcp__claude-flow__swarm_init { 
    topology: "hierarchical", 
    maxAgents: 4, 
    strategy: "minimal_fix_only" 
  }
  
  // Fix-focused agent deployment
  mcp__claude-flow__agent_spawn { type: "coordinator", name: "Fix Coordinator" }
  mcp__claude-flow__agent_spawn { type: "coder", name: "Infrastructure Connector" }
  mcp__claude-flow__agent_spawn { type: "coder", name: "State Machine Integrator" }
  mcp__claude-flow__agent_spawn { type: "tester", name: "Fix Validator" }
```

### **Clean Architecture Layer-Aligned Agent Responsibilities:**

#### **üéØ Clean Architecture Lead (Coordinator)**
- **Role**: Orchestrate phase transitions while maintaining Clean Architecture integrity
- **Layer Focus**: Cross-layer coordination ensuring dependency inversion principles
- **Tasks**: 
  - Coordinate domain-first integration approach
  - Ensure state machine integration respects Clean Architecture boundaries
  - Validate dependency flow: API ‚Üí Application ‚Üí Domain ‚Üê Infrastructure
- **Tools**: TodoWrite, architecture compliance validation, cross-layer coordination
- **Priority**: Maintain Clean Architecture patterns throughout phase transition fix

#### **üèóÔ∏è Domain Integration Architect (Analyst)**
- **Role**: Design state machine integration within Domain Layer constraints
- **Layer Focus**: Domain Layer (entities, events, services) + State Machine integration
- **Tasks**:
  - Analyze `domain/entities/game.py` and `engine/state_machine/` integration points
  - Design domain event emission from state machine phase transitions
  - Ensure state machine logic enhances rather than bypasses domain business rules
  - Map state machine phases to domain GamePhase enum consolidation
- **Tools**: Read, analysis, domain modeling, event design
- **Focus**: Phases 3, 4 - critical domain-state machine integration

#### **üíª Application Layer Developer (Coder)**
- **Role**: Modify use cases to integrate state machine coordination
- **Layer Focus**: Application Layer (`application/use_cases/`, `application/services/`)
- **Tasks**:
  - Update `application/use_cases/game/start_game.py` to use state machine instead of direct domain calls
  - Integrate state machine with existing event publishers
  - Ensure use case orchestration respects Clean Architecture patterns
  - Coordinate with infrastructure layer through defined interfaces
- **Tools**: Edit, MultiEdit, use case modification, interface implementation
- **Focus**: Phases 2, 3 - application layer integration work

#### **üîß Infrastructure Layer Developer (Coder)**
- **Role**: Enable event sourcing and enhance infrastructure support
- **Layer Focus**: Infrastructure Layer (`infrastructure/events/`, `infrastructure/dependencies.py`)
- **Tasks**:
  - Enable `USE_EVENT_SOURCING` feature flag in `infrastructure/feature_flags.py`
  - Enhance `CompositeEventPublisher` with state machine event integration
  - Optimize `EventStorePublisher` for phase transition event persistence
  - Ensure infrastructure adapts to domain and application layer needs
- **Tools**: Edit, configuration management, event infrastructure enhancement
- **Focus**: Phases 1, 2 - foundational infrastructure enabling

#### **‚öôÔ∏è State Machine Integration Expert (Specialist)**
- **Role**: Bridge state machine with Clean Architecture layers
- **Layer Focus**: Engine Layer + Cross-layer integration
- **Tasks**:
  - Integrate `GameStateMachine` with domain `Game` entity
  - Ensure state machine events emit proper domain events
  - Coordinate `PreparationState` automatic progression with domain business rules
  - Validate state machine integration doesn't violate Clean Architecture principles
- **Tools**: State machine modification, integration testing, validation
- **Focus**: Phases 3, 4 - specialized state machine integration

#### **üß™ Layer Boundary QA Engineer (Tester)**
- **Role**: Validate Clean Architecture compliance and integration correctness
- **Layer Focus**: Cross-layer testing and boundary validation
- **Tasks**:
  - Create tests ensuring no layer boundary violations
  - Validate dependency inversion is maintained post-integration
  - Test domain events flow correctly through all layers
  - Ensure state machine integration doesn't create circular dependencies
- **Tools**: Architecture testing, boundary validation, integration testing
- **Focus**: Phases 2, 3, 4 - comprehensive layer boundary testing

#### **üëÅÔ∏è Architecture Compliance Reviewer (Reviewer)**
- **Role**: Ensure all changes maintain Clean Architecture integrity
- **Layer Focus**: Cross-layer architecture compliance
- **Tasks**:
  - Review all code changes for Clean Architecture compliance
  - Validate dependency directions remain correct
  - Ensure domain layer remains pure business logic
  - Confirm infrastructure changes don't leak into higher layers
- **Tools**: Code review, architecture analysis, compliance validation
- **Focus**: All phases - continuous architecture compliance monitoring

#### **‚ö° Event Sourcing Performance Expert (Optimizer)**
- **Role**: Optimize event sourcing and state machine performance
- **Layer Focus**: Infrastructure Layer + Performance monitoring
- **Tasks**:
  - Optimize `CompositeEventPublisher` for minimal latency
  - Ensure event sourcing doesn't impact real-time game performance
  - Monitor phase transition performance after state machine integration
  - Validate event persistence doesn't create bottlenecks
- **Tools**: Performance testing, event sourcing optimization, monitoring
- **Focus**: Phases 2, 4, 5 - performance validation and optimization

### **Clean Architecture Coordination Pattern:**

```javascript
// MANDATORY CLEAN ARCHITECTURE COORDINATION HOOKS
Each agent MUST execute with layer-aware coordination:

1. BEFORE Starting Work:
   npx claude-flow@alpha hooks pre-task --description "[agent task]" --layer "[domain|application|infrastructure|api]"
   npx claude-flow@alpha hooks session-restore --session-id "clean-arch-phase-transition"
   npx claude-flow@alpha hooks architecture-validate --check-dependencies true

2. DURING Work (After EVERY Step):
   npx claude-flow@alpha hooks post-edit --file "[file]" --memory-key "clean-arch/[layer]/[agent]/[step]"
   npx claude-flow@alpha hooks notify --message "[what was accomplished]" --layer-impact "[affected layers]"
   npx claude-flow@alpha hooks boundary-check --validate-layer-compliance true

3. AFTER Completing Work:
   npx claude-flow@alpha hooks post-task --task-id "[task]" --analyze-performance true --architecture-compliance true
   npx claude-flow@alpha hooks dependency-validate --ensure-inversion-preserved true
```

### **Layer-Specific Coordination Requirements:**

#### **Domain Layer Changes** (Domain Integration Architect):
- Must validate: No infrastructure dependencies introduced
- Must ensure: Business rules remain pure and testable
- Must coordinate: Event emission integrates cleanly with application layer

#### **Application Layer Changes** (Application Layer Developer):
- Must validate: Use cases remain orchestration-focused
- Must ensure: State machine integration through proper interfaces
- Must coordinate: Domain and infrastructure layer coordination

#### **Infrastructure Layer Changes** (Infrastructure Layer Developer):
- Must validate: No business logic leakage into infrastructure
- Must ensure: Event sourcing enhances rather than complicates architecture
- Must coordinate: Performance impact on real-time game requirements

## üìä Success Metrics

### **Technical Metrics:**
- [ ] Event sourcing feature flag: `True`
- [ ] CompositeEventPublisher active with 2 publishers
- [ ] Game progression: PREPARATION ‚Üí DECLARATION < 10 seconds
- [ ] Event persistence: 100% of domain events stored
- [ ] State recovery: Complete game state reconstructable
- [ ] Performance: <10ms event latency

### **Functional Metrics:**
- [ ] Phase transition bug eliminated
- [ ] Full game flow functional end-to-end
- [ ] State persistence and recovery working
- [ ] No infinite loops or stuck states
- [ ] Error handling graceful and logged

### **Quality Metrics:**
- [ ] Test coverage: >90% for modified code
- [ ] Code review: All changes reviewed and approved
- [ ] Documentation: Architecture docs updated
- [ ] Performance: No regression in game response times

## üö® Risk Mitigation

### **High-Risk Areas:**
1. **State Machine Integration** - Complex logic, potential for breaking existing functionality
2. **Event Sourcing Performance** - Database I/O could impact game responsiveness
3. **Phase Progression Logic** - Risk of infinite loops or premature transitions

### **Mitigation Strategies:**
1. **Incremental Implementation** - Each phase builds on previous, with validation
2. **Comprehensive Testing** - Unit, integration, and end-to-end tests for each phase
3. **Rollback Plan** - Feature flag can disable event sourcing if issues arise
4. **Performance Monitoring** - Continuous monitoring during implementation

## üìÖ Timeline

### **Updated Granular Timeline**

**Total Estimated Time: 60 minutes with focused execution**

#### **Phase 1: Enable Event Sourcing (15 minutes)**
- Task 1.1 (Flag Enable): 5 minutes total
  - 1.1.1: Locate flag (2 min) 
  - 1.1.2: Change value (1 min)
  - 1.1.3: Test activation (2 min)
- Task 1.2 (Database): 6 minutes total
  - 1.2.1: Check file (1 min)
  - 1.2.2: Test connection (3 min) 
  - 1.2.3: Verify schema (2 min)
- Task 1.3 (Publisher): 4 minutes total
  - 1.3.1: Check setup (2 min)
  - 1.3.2: Test creation (2 min)
  - 1.3.3: Verify count (1 min)

#### **Phase 2: Connect State Machine (30 minutes)**
- Task 2.1 (Analysis): 10 minutes total
  - 2.1.1: Read use case (5 min)
  - 2.1.2: Find integration (3 min)
  - 2.1.3: Plan changes (2 min)
- Task 2.2 (Modification): 8 minutes total
  - 2.2.1: Backup (1 min)
  - 2.2.2: Replace call (5 min)
  - 2.2.3: Test compile (2 min)
- Task 2.3 (Verification): 10 minutes total
  - 2.3.1: Check prep state (5 min)
  - 2.3.2: Verify progression (3 min)
  - 2.3.3: Test calls (2 min)
- Task 2.4 (Testing): 23 minutes total
  - 2.4.1: Create test (10 min)
  - 2.4.2: Test isolation (5 min)
  - 2.4.3: Verify events (8 min)

#### **Phase 3: Test Integration (15 minutes)**
- Task 3.1 (Phase Progression): 10 minutes total
  - 3.1.1: Setup environment (2 min)
  - 3.1.2: Monitor progression (5 min)
  - 3.1.3: Verify no loops (3 min)
- Task 3.2 (Event Persistence): 10 minutes total
  - 3.2.1: Track events (3 min)
  - 3.2.2: Verify content (2 min)
  - 3.2.3: Test retrieval (5 min)
- Task 3.3 (WebSocket): 8 minutes total
  - 3.3.1: Mock connection (3 min)
  - 3.3.2: Monitor events (2 min)
  - 3.3.3: Verify timing (3 min)
- Task 3.4 (End-to-End): 10 minutes total
  - 3.4.1: Complete flow (5 min)
  - 3.4.2: Dual channels (3 min)
  - 3.4.3: Performance (2 min)

### **Task Dependencies**

#### **Sequential Dependencies:**
- **Phase 1 ‚Üí Phase 2**: Event sourcing must be enabled before connecting state machine
- **Phase 2 ‚Üí Phase 3**: State machine integration must be complete before testing

#### **Parallel Opportunities:**
- **Within Phase 1**: Tasks 1.2 and 1.3 can run parallel after 1.1 completes
- **Within Phase 2**: Tasks 2.3 can start while 2.2 is in progress
- **Within Phase 3**: Tasks 3.1, 3.2, 3.3 can run in parallel
- **Verification**: Task 3.4 must run after all other Phase 3 tasks complete

### **Critical Path:**
`1.1 ‚Üí 1.2 ‚Üí 2.1 ‚Üí 2.2 ‚Üí 2.4 ‚Üí 3.1 ‚Üí 3.4` = **45 minutes minimum**

### **Parallel Execution Opportunities:**
- Tasks with no dependencies can run simultaneously
- Multiple validation steps can be batched
- Testing phases can overlap where appropriate

---

## üéØ Minimal Fix Agent Deployment

### **Updated Deployment Command for Granular Tasks:**

```bash
# Deploy granular task swarm - EFFICIENT PARALLEL EXECUTION
npx claude-flow@alpha --agents 6 --topology mesh \
  --strategy parallel_granular_tasks \
  --task "Execute granular phase transition fix with optimal parallel coordination" \
  --constraint "follow granular task breakdown, respect dependencies" \
  --validate-dependencies true \
  --enable-parallel-execution true \
  --monitor-performance true \
  --total-time-limit 60min
```

### **Optimized Agent Configuration**

```javascript
// GRANULAR TASK DEPLOYMENT - PARALLEL EXECUTION
[Single Message - Batch Execution]:
  mcp__claude-flow__swarm_init { 
    topology: "mesh", 
    maxAgents: 6, 
    strategy: "parallel_granular_tasks" 
  }
  
  // Task-specific agent deployment
  mcp__claude-flow__agent_spawn { type: "coordinator", name: "Granular Task Coordinator" }
  mcp__claude-flow__agent_spawn { type: "coder", name: "Phase 1 Executor" }
  mcp__claude-flow__agent_spawn { type: "coder", name: "Phase 2 Executor" }
  mcp__claude-flow__agent_spawn { type: "tester", name: "Phase 3 Validator" }
  mcp__claude-flow__agent_spawn { type: "analyst", name: "Integration Analyst" }
  mcp__claude-flow__agent_spawn { type: "optimizer", name: "Performance Monitor" }
```

### **Granular Task Execution Instructions:**

Each agent receives specific granular task assignments with clear success criteria:

#### **Phase 1 Executor Instructions:**
```
üéØ PHASE 1 TASKS: Enable Event Sourcing Foundation (15 minutes)

Your assigned granular tasks:
- 1.1.1: Locate feature flag file (2 min)
- 1.1.2: Change USE_EVENT_SOURCING flag (1 min) 
- 1.1.3: Test flag activation (2 min)
- 1.2.1-1.2.3: Database verification (6 min, parallel with 1.3)
- 1.3.1-1.3.3: Publisher validation (4 min, parallel with 1.2)

SUCCESS CRITERIA for each task are clearly defined in plan.
Execute in optimal order: 1.1 sequential, then 1.2 & 1.3 parallel.
Report completion of each granular task to coordinator.
```

#### **Phase 2 Executor Instructions:**
```
üéØ PHASE 2 TASKS: Connect State Machine (30 minutes)

Your assigned granular tasks:
- 2.1.1-2.1.3: Use case analysis (10 min)
- 2.2.1-2.2.3: State machine integration (8 min)
- 2.3.1-2.3.3: Domain integration verification (10 min, can start during 2.2)
- 2.4.1-2.4.3: Integration testing prep (23 min)

CRITICAL: This is the core fix - replace direct domain calls with state machine.
Execute with careful coordination, validate each step before proceeding.
Create backup before modifications as specified in task 2.2.1.
```

#### **Phase 3 Validator Instructions:**
```
üéØ PHASE 3 TASKS: Test Integration (15 minutes)

Your assigned granular tasks:
- 3.1.1-3.1.3: Phase progression validation (10 min)
- 3.2.1-3.2.3: Event persistence validation (10 min) 
- 3.3.1-3.3.3: WebSocket validation (8 min)
- 3.4.1-3.4.3: End-to-end validation (10 min)

PARALLEL EXECUTION: Tasks 3.1, 3.2, 3.3 run simultaneously.
Task 3.4 executes only after 3.1-3.3 complete successfully.
This validates the entire fix works end-to-end.
```

#### **Coordinator Instructions:**
```
üéØ COORDINATION: Manage Dependencies and Critical Path

Your responsibilities:
- Track all granular tasks via TodoWrite
- Monitor critical path: 1.1 ‚Üí 1.2 ‚Üí 2.1 ‚Üí 2.2 ‚Üí 2.4 ‚Üí 3.1 ‚Üí 3.4
- Enable parallel execution where dependencies allow
- Coordinate rollback if any critical task fails
- Validate total time stays within 60-minute limit

DEPENDENCY MANAGEMENT: Phase 1 must complete before Phase 2 starts.
Phase 2 must complete before Phase 3 starts.
Within phases, enable maximum parallelism.
```

### **Granular Task Approach Benefits:**

1. **‚öôÔ∏è Systematic Execution**: Each task has clear 2-10 minute time estimates and success criteria
2. **üîÑ Optimal Parallelism**: Tasks 1.2 & 1.3 parallel, Tasks 3.1-3.3 parallel - reduces total time to 60 minutes  
3. **üìä Clear Dependencies**: Critical path mapped, no guesswork on execution order
4. **‚úÖ Validation at Each Step**: Every granular task has specific validation commands and success criteria
5. **üéØ Precise Scope**: Each agent knows exactly which 8-12 granular tasks they're responsible for
6. **üîí Risk Mitigation**: Backup creation and rollback procedures defined for critical modifications
7. **üìà Progress Tracking**: 24 total granular tasks allow precise progress monitoring (4% per task)
8. **‚ö° Time Optimization**: 45-minute critical path vs 60-minute total allows 15 minutes of parallel execution buffer

### **Granular Task Success Metrics:**

#### **Task Completion Tracking (24 Total Tasks):**
**Phase 1 Tasks (9 tasks = 37.5% of total)**
- [ ] 1.1.1: Flag file located (4.2% complete)
- [ ] 1.1.2: Flag value changed (8.3% complete)  
- [ ] 1.1.3: Flag activation tested (12.5% complete)
- [ ] 1.2.1: EventStore file verified (16.7% complete)
- [ ] 1.2.2: Database connection tested (20.8% complete)
- [ ] 1.2.3: Database schema verified (25% complete)
- [ ] 1.3.1: Publisher setup checked (29.2% complete)
- [ ] 1.3.2: Publisher creation tested (33.3% complete)
- [ ] 1.3.3: Publisher count verified (37.5% complete)

**Phase 2 Tasks (12 tasks = 50% of total)**
- [ ] 2.1.1: Use case implementation read (41.7% complete)
- [ ] 2.1.2: Integration points identified (45.8% complete)
- [ ] 2.1.3: Modification approach planned (50% complete)
- [ ] 2.2.1: Implementation backed up (54.2% complete)
- [ ] 2.2.2: Domain call replaced (58.3% complete)
- [ ] 2.2.3: Compilation tested (62.5% complete)
- [ ] 2.3.1: PreparationState checked (66.7% complete)
- [ ] 2.3.2: Progression logic verified (70.8% complete)
- [ ] 2.3.3: Domain method calls tested (75% complete)
- [ ] 2.4.1: Integration test created (79.2% complete)
- [ ] 2.4.2: Use case tested in isolation (83.3% complete)
- [ ] 2.4.3: Event publishing verified (87.5% complete)

**Phase 3 Tasks (12 tasks = 50% of total)**
- [ ] 3.1.1: Test environment setup (91.7% complete)
- [ ] 3.1.2: Phase progression monitored (95.8% complete)
- [ ] 3.1.3: No loops verified (100% complete)
- [ ] 3.2.1: Event tracking triggered (continuing...)
- [ ] 3.2.2: Event content verified
- [ ] 3.2.3: Event retrieval tested
- [ ] 3.3.1: WebSocket connection mocked
- [ ] 3.3.2: WebSocket events monitored
- [ ] 3.3.3: Timing regression verified  
- [ ] 3.4.1: Complete flow tested
- [ ] 3.4.2: Dual channels validated
- [ ] 3.4.3: Performance baseline checked

#### **Core Functionality Validation:**
- [ ] ‚úÖ Game progresses PREPARATION ‚Üí DECLARATION (Tasks 3.1.1-3.1.3)
- [ ] ‚úÖ Events persist to SQLite database (Tasks 3.2.1-3.2.3)
- [ ] ‚úÖ WebSocket broadcasting maintained (Tasks 3.3.1-3.3.3)
- [ ] ‚úÖ End-to-end integration works (Tasks 3.4.1-3.4.3)

#### **Time and Quality Metrics:**
- [ ] ‚úÖ Phase 1 completed within 15 minutes (Tasks 1.1.1-1.3.3)
- [ ] ‚úÖ Phase 2 completed within 30 minutes (Tasks 2.1.1-2.4.3)  
- [ ] ‚úÖ Phase 3 completed within 15 minutes (Tasks 3.1.1-3.4.3)
- [ ] ‚úÖ Total execution time ‚â§ 60 minutes
- [ ] ‚úÖ All validation commands executed successfully
- [ ] ‚úÖ Critical path tasks completed in sequence
- [ ] ‚úÖ Parallel tasks executed simultaneously where possible

This granular approach provides precise progress tracking, optimal parallel execution, and systematic validation at each step. Ready to execute the granular task approach with 6-agent swarm coordination!