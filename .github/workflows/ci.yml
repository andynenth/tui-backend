name: CI/CD Pipeline

on:
  push:
    branches: [ main, simplified-architecture ]
  pull_request:
    branches: [ main ]

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '22'
  DOCKER_REGISTRY: ${{ secrets.DOCKER_REGISTRY }}

jobs:
  # Stage 1: Fast feedback with unit tests and linting
  unit-tests:
    name: Unit Tests & Code Quality
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Set up Node.js ${{ env.NODE_VERSION }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}

    - name: Cache npm dependencies
      uses: actions/cache@v4
      with:
        path: ~/.npm
        key: ${{ runner.os }}-node-${{ hashFiles('frontend/package-lock.json') }}
        restore-keys: |
          ${{ runner.os }}-node-

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r backend/requirements-test.txt

    - name: Install Frontend dependencies
      working-directory: frontend
      run: npm ci

    - name: Python Code Formatting (Black)
      working-directory: backend
      run: black . --check --diff || echo "::warning::Black formatting issues found. Run 'black .' locally to fix."
      continue-on-error: true

    - name: Python Code Quality (Pylint)
      working-directory: backend
      run: pylint engine/ api/ --exit-zero --max-line-length=120 --disable=C0111,R0903,R0913,W0613

    - name: Frontend ESLint
      working-directory: frontend
      run: npm run lint -- --max-warnings 150 --format=compact
      continue-on-error: true

    - name: Frontend TypeScript Check
      working-directory: frontend
      run: npm run type-check
      continue-on-error: true

    - name: Backend Unit Tests
      working-directory: backend
      run: |
        # Try with coverage first, fallback to basic pytest
        python -m pytest tests/unit/ -v --cov=. --cov-report=term-missing || python -m pytest tests/unit/ -v || echo "::warning::Some unit tests may have failed"
      env:
        PYTHONPATH: ${{ github.workspace }}/backend
      continue-on-error: true

    - name: Frontend Unit Tests
      working-directory: frontend
      run: npm test -- --coverage --watchAll=false || echo "::warning::Some frontend tests failed"
      continue-on-error: true

    - name: Upload Backend Coverage
      uses: codecov/codecov-action@v3
      with:
        file: backend/coverage.xml
        flags: backend
        name: backend-coverage

    - name: Upload Frontend Coverage
      uses: codecov/codecov-action@v3
      with:
        file: frontend/coverage/lcov.info
        flags: frontend
        name: frontend-coverage

  # Stage 2: Integration tests (moderate speed)
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r backend/requirements-test.txt

    - name: Backend Integration Tests
      working-directory: backend
      run: |
        pytest tests/integration/ -v --maxfail=5
      env:
        PYTHONPATH: ${{ github.workspace }}/backend

  # Stage 3: End-to-end tests (comprehensive but slower)
  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: integration-tests
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Set up Node.js ${{ env.NODE_VERSION }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}

    - name: Cache npm dependencies
      uses: actions/cache@v4
      with:
        path: ~/.npm
        key: ${{ runner.os }}-node-${{ hashFiles('frontend/package-lock.json') }}
        restore-keys: |
          ${{ runner.os }}-node-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip && pip install -r requirements.txt -r backend/requirements-test.txt
        cd frontend && npm ci

    - name: Build Frontend
      working-directory: frontend
      run: npm run build

    - name: Backend E2E Tests
      working-directory: backend
      run: |
        pytest tests/e2e/ -v --maxfail=3
      env:
        PYTHONPATH: ${{ github.workspace }}/backend

  # Stage 4: Docker build and security scanning
  docker-build:
    name: Docker Build & Security Scan
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Build Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        push: false
        tags: liap-tui:test
        load: true
        cache-from: type=gha
        cache-to: type=gha,mode=max

    - name: Verify Docker image exists
      run: docker images | grep liap-tui || echo "::warning::Docker image not found"

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: 'liap-tui:test'
        format: 'sarif'
        output: 'trivy-results.sarif'
      continue-on-error: true

    - name: Upload Trivy scan results
      uses: github/codeql-action/upload-sarif@v3
      if: always() && hashFiles('trivy-results.sarif') != ''
      with:
        sarif_file: 'trivy-results.sarif'

  # Stage 5: Deploy (only on main branch)
  deploy:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, e2e-tests, docker-build]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Login to Docker Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ secrets.DOCKER_REGISTRY }}
        username: ${{ secrets.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_PASSWORD }}
      if: ${{ env.DOCKER_REGISTRY != '' }}

    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        push: ${{ env.DOCKER_REGISTRY != '' }}
        tags: |
          ${{ secrets.DOCKER_REGISTRY }}/liap-tui:latest
          ${{ secrets.DOCKER_REGISTRY }}/liap-tui:${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

    - name: Deploy notification
      run: |
        echo "ðŸš€ Deployment completed successfully!"
        echo "Image: ${{ secrets.DOCKER_REGISTRY }}/liap-tui:${{ github.sha }}"
      if: success()

  # Performance monitoring job
  performance-check:
    name: Performance Monitoring
    runs-on: ubuntu-latest
    needs: e2e-tests
    if: github.event_name == 'pull_request'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      working-directory: backend
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt -r requirements-test.txt

    - name: Run Performance Tests
      working-directory: backend
      run: |
        pytest tests/e2e/performance/ -v --benchmark-only --benchmark-json=benchmark.json
      env:
        PYTHONPATH: ${{ github.workspace }}/backend

    - name: Performance Report Comment
      uses: benchmark-action/github-action-benchmark@v1
      if: always()
      with:
        tool: 'pytest'
        output-file-path: backend/benchmark.json
        comment-on-alert: true
        github-token: ${{ secrets.GITHUB_TOKEN }}